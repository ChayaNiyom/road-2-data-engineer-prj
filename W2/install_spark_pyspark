# !apt-get update                                                                          # Update all package in this VM
# !apt-get install openjdk-8-jdk-headless -qq > /dev/null                                  # Install Java Development Kit (Important for Spark Installation )
# !wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz # Install Spark 3.1.2
# !tar xzvf spark-3.1.2-bin-hadoop2.7.tgz                                                  # Unzip Spark 3.1.2 file
# !pip install -q findspark==1.3.0                                                         # Install Python package to connect Spark 
-------------------------------------
# (Set enviroment variable to let Python notice Spark)
# import os
# os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
# os.environ["SPARK_HOME"] = "/content/spark-3.1.2-bin-hadoop2.7"
-------------------------------------
# (Install PySpark on Python)
# !pip install pyspark==3.1.2
